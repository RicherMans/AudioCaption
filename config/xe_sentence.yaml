outputpath: experiments/hospital

feature_file: data/hospital/fbank.hdf5
caption_file: data/hospital/labels/zh_dev.json
vocab_file: data/hospital/vocab_zh.pth
zh: True
dataloader_args:
    batch_size: 32
    num_workers: 4
train_percent: 90
augments: []

scaler: StandardScaler # Can be any of sklearn.preprocessing that supports fit_partial
scaler_args:
    with_std : True
    with_mean : True        

encodermodel: RNNEncoder
encodermodel_args:
    num_layers: 1
    dropout: 0.0
    # Enables the passing of the hidden encoder state to the decoder
    use_hidden: False
    # Can be time, mean ( for last timestep, mean reduction)
    representation: mean
    hidden_size: 512
decodermodel: RNNDecoder
decodermodel_args:
    num_layers: 1
    hidden_size: 512
model: CaptionSentenceModel
model_args:
    embed_size: 256
    dropout: 0.3
    seq_output_size: 768
#pretrained_word_embedding: data/hospital/embeddings/bert_word_zh.npy
sentence_embedding: data/hospital/embeddings/originbert_dev.pkl
seq_loss_ratio: 10

improvecriterion: score # Can be acc | loss | score

optimizer: Adam
optimizer_args:
    lr: 0.0005
    weight_decay: 0.0
epochs: 25
scheduler: ReduceLROnPlateau
scheduler_args:
    mode: min
    factor: 0.1
    patience: 5
    threshold: 0.001

